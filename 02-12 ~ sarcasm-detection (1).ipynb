{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Surestart Action Item Day 5\nThis notebook will train and test a basic neural network, using Keras, to determine whether a headline is sarcastic or not.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Necessary packages\nimport pandas as pd\nimport numpy as np5\nimport os\nimport json\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.model_selection import cross_val_score as cvs\nimport nltk\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport keras\nimport tensorflow as tf\nfrom keras import models\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom tensorflow.keras.losses import MeanSquaredError as mse\nimport sklearn.metrics\nfrom sklearn.metrics import confusion_matrix as cm\nfrom sklearn.metrics import precision_score, recall_score","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Getting pathnames for each file in the input folder\nfor dirname, _, filenames in os.walk('/kaggle/input/news-headlines-dataset-for-sarcasm-detection'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n#Function to parse data\ndef parse_data(file):\n    for l in open(file,'r'):\n        yield json.loads(l)\n\n#Taking in the data in one of the json files (I'm using the slightly larger one)\ndata = list(parse_data(\"/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\"))\ndata[0]","execution_count":13,"outputs":[{"output_type":"stream","text":"/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\n/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"{'is_sarcastic': 1,\n 'headline': 'thirtysomething scientists unveil doomsday clock of hair loss',\n 'article_link': 'https://www.theonion.com/thirtysomething-scientists-unveil-doomsday-clock-of-hai-1819586205'}"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"****We need to separate the data from this list into X and y****  \nOur X is going to be a vectorized list of words from the headline.  \nOur y is going to be \"is_sarcastic\".  \nTo do this, we're going to use some NLP packages  "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating our X variable\nvectorizer = TfidfVectorizer(max_features=50, use_idf=False)\nheadlines = [i['headline'] for i in data]\nX = vectorizer.fit_transform(headlines).toarray()\n\n#Creating our y variable\ny = np.ravel([i['is_sarcastic'] for i in data])\n\n#Creating a train and test split\nX_train, X_test, y_train, y_test = tts(X, y, test_size = 0.2, random_state = 1693)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we're going to build the model with its layers\n\n#Initialize the model\nmodel = Sequential()\n\n#Add the input layer\nmodel.add(Dense(24, activation = 'softmax', input_shape = (50,)))\n\n#Add first hidden layer\nmodel.add(Dense(12, activation = 'softmax'))\n\n#Add second hidden layer\nmodel.add(Dense(8, activation = 'softmax'))\n\n#Tried adding third layer, didn't change much\nmodel.add(Dense(4, activation = 'softmax'))\n\n#Add output layer\nmodel.add(Dense(1, activation='sigmoid'))","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we're going to compile the model\n#Our loss function is binary crossentropy\n#Our optimizer is adam\n\nmodel.compile(loss = 'binary_crossentropy', \n              optimizer = 'adam',\n              metrics = ['accuracy', 'mse'])\n\n#We're going to also fit the model\n#We're going to do 20 epochs\n#The batch size will be 224 to get ~100 iterations per epoch\nmodel.fit(X_train, y_train, epochs = 20,\n          batch_size = 224, verbose = 1)","execution_count":38,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n103/103 [==============================] - 1s 1ms/step - loss: 0.7164 - accuracy: 0.5244 - mse: 0.2611\nEpoch 2/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.7017 - accuracy: 0.5191 - mse: 0.2542\nEpoch 3/20\n103/103 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5234 - mse: 0.2504\nEpoch 4/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5220 - mse: 0.2497\nEpoch 5/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5197 - mse: 0.2497\nEpoch 6/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5191 - mse: 0.2496\nEpoch 7/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5205 - mse: 0.2495\nEpoch 8/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5207 - mse: 0.2494\nEpoch 9/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.5259 - mse: 0.2487\nEpoch 10/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.5245 - mse: 0.2460\nEpoch 11/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.6636 - accuracy: 0.6104 - mse: 0.2353\nEpoch 12/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.6226 - accuracy: 0.7189 - mse: 0.2155\nEpoch 13/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.5911 - accuracy: 0.7215 - mse: 0.2011\nEpoch 14/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.7224 - mse: 0.1959\nEpoch 15/20\n103/103 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7253 - mse: 0.1906\nEpoch 16/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.5613 - accuracy: 0.7251 - mse: 0.1886\nEpoch 17/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7236 - mse: 0.1886\nEpoch 18/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.5565 - accuracy: 0.7277 - mse: 0.1867\nEpoch 19/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.5540 - accuracy: 0.7286 - mse: 0.1856\nEpoch 20/20\n103/103 [==============================] - 0s 1ms/step - loss: 0.5517 - accuracy: 0.7271 - mse: 0.1850\n","name":"stdout"},{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f4ff271ff50>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Next, we'll test the model on the test dataset we set aside\n\n#Prediction on the X_test data, round each to an integer (either 0 or 1)\ny_pred = np.around(model.predict(X_test))\n\n#We're going to now look at the accuracy and loss\nscore = model.evaluate(X_test, y_test, verbose=1)\nprint(score)\n\n#We'll print precision and recall too\nprint(f\"Precision: {precision_score(y_test, y_pred)}\")\nprint(f\"Recall: {recall_score(y_test, y_pred)}\")","execution_count":39,"outputs":[{"output_type":"stream","text":"179/179 [==============================] - 0s 832us/step - loss: 0.5662 - accuracy: 0.7072 - mse: 0.1917\n[0.566223680973053, 0.7071977853775024, 0.19168050587177277]\nPrecision: 0.6524353577871317\nRecall: 0.8066914498141264\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we're going to make a confusion matri\n#The rows are the known labels, the columns are the predicted labels\nmatrix = cm(y_test, y_pred)\ndf = pd.DataFrame(columns = ['', 'is_sarcastic', 'not_sarcastic'])\ndf.loc[len(df)] = ['is_sarcastic', matrix[0][0], matrix[0][1]]\ndf.loc[len(df)] = ['not_sarcastic', matrix[1][0], matrix[1][1]]\nprint(df)","execution_count":40,"outputs":[{"output_type":"stream","text":"                 is_sarcastic not_sarcastic\n0   is_sarcastic         1878          1156\n1  not_sarcastic          520          2170\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
